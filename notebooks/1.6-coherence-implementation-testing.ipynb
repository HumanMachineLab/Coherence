{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dc7697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run if working locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88ee84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pickle\n",
    "import os, sys\n",
    "import torch\n",
    "import config\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, config.root_path)\n",
    "\n",
    "from src.dataset.dataset import RawData\n",
    "from src.dataset.wikisection_preprocessing import (\n",
    "    tokenize,\n",
    "    clean_sentence,\n",
    "    preprocess_text_segmentation,\n",
    "    format_data_for_db_insertion,\n",
    ")\n",
    "from src.dataset.utils import truncate_by_token\n",
    "from db.dbv2 import Table, AugmentedTable, TrainTestTable\n",
    "import pprint\n",
    "\n",
    "from utils.metrics import windowdiff, pk\n",
    "\n",
    "from src.bertkeywords.src.similarities import Embedding, Similarities\n",
    "from src.bertkeywords.src.keywords import Keywords\n",
    "from src.encoders.coherence_v2 import Coherence\n",
    "from src.dataset.utils import flatten, dedupe_list, truncate_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bb2458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: qmsum_academic\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"academic\"\n",
    "table = Table(dataset_type)\n",
    "augmented_table = AugmentedTable(dataset_type)\n",
    "train_test_table = TrainTestTable(dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfd59c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = table.get_all()\n",
    "\n",
    "text_data = [x[1] for x in data]\n",
    "text_labels = [x[2] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcccad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segments = table.get_all_segments()\n",
    "text_segments = [[y[1] for y in x] for x in all_segments]\n",
    "segments_labels = [[1 if i == 0 else 0 for i, y in enumerate(x)] for x in all_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e84fe0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = [item for sublist in all_segments for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e6918d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 84698, 267.18611987381706)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_segments), len(all_samples), (len(all_samples) / len(all_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eff59-b5e2-4e73-828d-97cb475eaa65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295657fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 5\n",
    "max_tokens = 400\n",
    "\n",
    "for i, (segment, labels) in enumerate(\n",
    "    zip(text_segments[:samples], segments_labels[:samples])\n",
    "):\n",
    "    for sentence, label in zip(segment, labels):\n",
    "        # this is the training case. During inference, we will have no idea\n",
    "        # when segments start and when they end.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "467789d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_labels[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e420ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# initialize the coherence library\n",
    "max_words_per_step = 3\n",
    "coherence = Coherence(max_words_per_step=max_words_per_step, kb_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6870992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_average(weighted_similarities, weights):\n",
    "    return sum(weighted_similarities) / sum(weights)\n",
    "\n",
    "\n",
    "# importance testing\n",
    "def compare_coherent_words(\n",
    "    coherence_map,\n",
    "    keywords_current,\n",
    "    suppress_errors=False,\n",
    "    same_word_multiplier=2,  # if set to 1, don't amplify the same words found\n",
    "    no_same_word_penalty=2,  # if set to 1, don't penalize for not finding the same word.\n",
    "):\n",
    "    word_comparisons = []\n",
    "    weights = []\n",
    "    for i, keywords in enumerate(coherence_map[::-1]):\n",
    "        for word_tuple in keywords:\n",
    "            word = word_tuple[0]\n",
    "            for second_word_tuple in keywords_current:\n",
    "                second_word = second_word_tuple[0]\n",
    "                second_word_importance = second_word_tuple[1]\n",
    "\n",
    "                try:\n",
    "                    word_one_emb = word_tuple[2]\n",
    "                    word_two_emb = second_word_tuple[2]\n",
    "\n",
    "                    if same_word_multiplier > 1:\n",
    "                        flattened_coherence_words_only = [\n",
    "                            element[0]\n",
    "                            for sublist in coherence_map\n",
    "                            for element in sublist\n",
    "                        ]\n",
    "\n",
    "                        num_occurrences = flattened_coherence_words_only.count(\n",
    "                            second_word\n",
    "                        )\n",
    "\n",
    "                        if num_occurrences > 0:\n",
    "                            # amplify words that are found as duplicates in the coherence map\n",
    "                            # if the word shows up 1 time, amplify the weight by 2 times\n",
    "                            weighting_multiplier = flattened_coherence_words_only.count(\n",
    "                                second_word\n",
    "                            ) + (same_word_multiplier - 1)\n",
    "                        else:\n",
    "                            # no same word penalty\n",
    "                            weighting_multiplier = (\n",
    "                                1 / no_same_word_penalty\n",
    "                            )  # reduce the importance of this word\n",
    "\n",
    "                    else:\n",
    "                        weighting_multiplier = 1  # set to 1 in case this is turned off.\n",
    "\n",
    "                    # this weight is a recipricol function that will grow smaller the further the keywords are away\n",
    "                    # we want to put more importance on the current words, so we apply twice as much weight.\n",
    "                    if i == 0:\n",
    "                        weight = (weighting_multiplier * 2) / (i + 1)\n",
    "                    else:\n",
    "                        weight = (weighting_multiplier * 1) / (i + 1)\n",
    "\n",
    "                    # multiply the weighting factor by the importance of the second word\n",
    "                    weight *= second_word_importance\n",
    "\n",
    "                    word_comparisons.append(\n",
    "                        (\n",
    "                            word,\n",
    "                            second_word,\n",
    "                            weight\n",
    "                            * coherence.embedding_lib.get_similarity(\n",
    "                                torch.Tensor(word_one_emb), torch.Tensor(word_two_emb)\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    weights.append(weight)\n",
    "                except AssertionError as e:\n",
    "                    if not suppress_errors:\n",
    "                        print(e, word, second_word)\n",
    "\n",
    "    return word_comparisons, weights\n",
    "\n",
    "\n",
    "# TODO: add weighted average: https://www.google.com/search?q=weighted+average&rlz=1C5CHFA_enCA1019CA1024&sxsrf=APwXEdcb6dhJ5L_mvWvrWr4AxQcxOFB01g:1681098698316&tbm=isch&source=iu&ictx=1&vet=1&fir=V-LTDKtCElo89M%252C2WVwd1NrPkHFOM%252C_%253BVGk_lj0HALhXQM%252C2WVwd1NrPkHFOM%252C_%253ByzfbB4i3SpPTFM%252C5e7an03wLAdfhM%252C_%253B47HYmoDH6WlThM%252CsRXbJWfpyOLEOM%252C_%253BOsB4jtfzenfuyM%252CHKcmLkpfJ3xWqM%252C_&usg=AI4_-kRmBXgUWAm_nR3vDsLT17TqM5AvSQ&sa=X&ved=2ahUKEwi6hvvVtJ7-AhXJkIkEHe4JCX4Q_h16BAgoEAE#imgrc=V-LTDKtCElo89M\n",
    "def coherence_tester(\n",
    "    text_data,\n",
    "    text_labels,\n",
    "    max_tokens=128,\n",
    "    max_str_length=30,\n",
    "    prediction_thresh=0.48,\n",
    "    coherence_threshold=0.2,\n",
    "    pruning=1,  # remove one sentence worth of keywords\n",
    "    pruning_min=6,  # remove the first sentence in the coherence map once it grows passed 6\n",
    "    dynamic_threshold=False,\n",
    "    coherence_dump_on_prediction=False,\n",
    "    threshold_warmup=10,  # number of iterations before using dynamic threshold\n",
    "    last_n_threshold=5,  # will only consider the last n thresholds for dynamic threshold\n",
    "    batch_size=10,\n",
    "):\n",
    "    coherence_map = []\n",
    "    predictions = []\n",
    "    thresholds = []\n",
    "\n",
    "    prev_sentence = None\n",
    "\n",
    "    # set up batching\n",
    "    for batch_num in range(0, len(text_data) // batch_size):\n",
    "        # create the current batch to iterate over.\n",
    "        # this method relies on previous sentence as it always keeps track\n",
    "        curr_batch = text_data[\n",
    "            batch_num * batch_size : batch_num * batch_size + batch_size\n",
    "        ]\n",
    "\n",
    "        curr_batch_labels = text_labels[\n",
    "            batch_num * batch_size : batch_num * batch_size + batch_size\n",
    "        ]\n",
    "\n",
    "        for i, (row, label) in enumerate(zip(curr_batch, curr_batch_labels)):\n",
    "            threshold = prediction_thresh\n",
    "            if dynamic_threshold and (i + 1) > threshold_warmup:\n",
    "                last_n_thresholds = thresholds[(0 - last_n_threshold) :]\n",
    "                last_n_thresholds.sort()\n",
    "                mid = len(last_n_thresholds) // 2\n",
    "                threshold = (last_n_thresholds[mid] + last_n_thresholds[~mid]) / 2\n",
    "                print(f\"median threshold: {threshold}\")\n",
    "            # compare the current sentence to the previous one\n",
    "            if prev_sentence is None:\n",
    "                predictions.append(\n",
    "                    (torch.tensor(0, dtype=torch.int8), 0)\n",
    "                )  # predict a 0 since it's the start\n",
    "                print(f\"Label: {label}, Prediction: {0}\")\n",
    "                prev_sentence = row\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Sample Number: {i}\")\n",
    "\n",
    "                row = truncate_by_token(row, max_tokens)\n",
    "                prev_row = truncate_by_token(prev_sentence, max_tokens)\n",
    "\n",
    "                cohesion, keywords_prev, keywords_current = coherence.get_coherence(\n",
    "                    [row, prev_row], coherence_threshold=coherence_threshold\n",
    "                )\n",
    "\n",
    "                # add the keywords to the coherence map\n",
    "                coherence_map.append(cohesion)\n",
    "                if pruning > 0 and len(coherence_map) >= pruning_min:\n",
    "                    print(\"pruning...\", len(coherence_map))\n",
    "                    coherence_map = coherence_map[\n",
    "                        pruning:\n",
    "                    ]  # remove the pruning amount from the beginning of the list\n",
    "                    print(\"done pruning...\", len(coherence_map))\n",
    "\n",
    "                # truncate the strings for printing\n",
    "                truncated_row = truncate_string(row, max_str_length)\n",
    "                truncated_prev_row = truncate_string(prev_row, max_str_length)\n",
    "                print(\n",
    "                    f\"Coherence Map: {[[x[0] for x in c] for c in coherence_map]}, KW Curr: {[x[0] for x in keywords_current]}\"\n",
    "                )\n",
    "\n",
    "                # compute the word comparisons between the previous (with the coherence map)\n",
    "                # and the current (possibly the first sentence in a new segment)\n",
    "                word_comparisons_with_coherence, weights = compare_coherent_words(\n",
    "                    [*coherence_map, keywords_prev], keywords_current\n",
    "                )\n",
    "\n",
    "                similarities_with_coherence = [\n",
    "                    comparison[2] for comparison in word_comparisons_with_coherence\n",
    "                ]\n",
    "                \n",
    "                weighted_avg_similarity_with_coherence = get_weighted_average(\n",
    "                    similarities_with_coherence, weights\n",
    "                )\n",
    "                print(f\"weighted: {weighted_avg_similarity_with_coherence}\")\n",
    "\n",
    "                # if the two sentences are similar, create a cohesive prediction\n",
    "                # otherwise, predict a new segment\n",
    "                if weighted_avg_similarity_with_coherence > threshold:\n",
    "                    print(\n",
    "                        f\"Label: {label}, Prediction: {0}, logit: {weighted_avg_similarity_with_coherence}\"\n",
    "                    )\n",
    "                    predictions.append((weighted_avg_similarity_with_coherence, 0))\n",
    "                else:\n",
    "                    if coherence_dump_on_prediction:\n",
    "                        # start of a new segment, empty the map\n",
    "                        coherence_map = []\n",
    "                    print(\n",
    "                        f\"Label: {label}, Prediction: {1}, logit: {weighted_avg_similarity_with_coherence}\"\n",
    "                    )\n",
    "                    predictions.append((weighted_avg_similarity_with_coherence, 1))\n",
    "\n",
    "                thresholds.append(weighted_avg_similarity_with_coherence)\n",
    "                print(\"===============================================\")\n",
    "\n",
    "                prev_sentence = row\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca71b4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0, Prediction: 0\n",
      "Sample Number: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_coherence() got an unexpected keyword argument 'coherence_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m max_str_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      6\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m text_labels[start : start \u001b[38;5;241m+\u001b[39m num_samples]\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence_tester\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_str_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_str_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 136\u001b[0m, in \u001b[0;36mcoherence_tester\u001b[0;34m(text_data, text_labels, max_tokens, max_str_length, prediction_thresh, coherence_threshold, pruning, pruning_min, dynamic_threshold, coherence_dump_on_prediction, threshold_warmup, last_n_threshold, batch_size)\u001b[0m\n\u001b[1;32m    133\u001b[0m row \u001b[38;5;241m=\u001b[39m truncate_by_token(row, max_tokens)\n\u001b[1;32m    134\u001b[0m prev_row \u001b[38;5;241m=\u001b[39m truncate_by_token(prev_sentence, max_tokens)\n\u001b[0;32m--> 136\u001b[0m cohesion, keywords_prev, keywords_current \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_row\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoherence_threshold\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# add the keywords to the coherence map\u001b[39;00m\n\u001b[1;32m    141\u001b[0m coherence_map\u001b[38;5;241m.\u001b[39mappend(cohesion)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_coherence() got an unexpected keyword argument 'coherence_threshold'"
     ]
    }
   ],
   "source": [
    "start = 100\n",
    "num_samples = 50\n",
    "max_tokens = 128  # want to keep this under 512\n",
    "max_str_length = 30\n",
    "\n",
    "true_labels = text_labels[start : start + num_samples]\n",
    "\n",
    "predictions = coherence_tester(\n",
    "    text_data[start : start + num_samples],\n",
    "    true_labels,\n",
    "    max_tokens=max_tokens,\n",
    "    max_str_length=max_str_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3a93727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"print([x[1] for x in predictions])\\nprint(true_labels)\";\n",
       "                var nbb_formatted_code = \"print([x[1] for x in predictions])\\nprint(true_labels)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print([x[1] for x in predictions])\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "640bc1ce-1ea5-42ac-a1a0-c3810713a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_predictions = [1,0,1,0,1]\n",
    "true_labels = [1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "581e160e-43da-4402-baa0-82fd6ad07763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_string = \"\".join(map(str,modified_predictions))\n",
    "true_string = \"\".join(map(str,true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08387b87-d7d0-4326-9221-de1cb94e05e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('10101', '11111')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_string, true_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61e7863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"pred_string = \\\"\\\".join(str([x[1] for x in predictions]))\\ntrue_string = \\\"\\\".join(str(true_labels))\";\n",
       "                var nbb_formatted_code = \"pred_string = \\\"\\\".join(str([x[1] for x in predictions]))\\ntrue_string = \\\"\\\".join(str(true_labels))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_string = \"\".join(str([x[1] for x in predictions]))\n",
    "true_string = \"\".join(str(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19af16ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\";\n",
       "                var nbb_formatted_code = \"avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db43c420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5\n",
      "wd = 0.2876712328767123\n",
      "pk = 0.273972602739726\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\";\n",
       "                var nbb_formatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wd_score = windowdiff(pred_string, true_string, avg_k)\n",
    "pk_score = pk(pred_string, true_string, avg_k)\n",
    "\n",
    "print(f\"k = {avg_k}\")\n",
    "print(f\"wd = {wd_score}\")\n",
    "print(f\"pk = {pk_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb16194",
   "metadata": {},
   "source": [
    "## Prediction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81b6b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"pred_thresholds = [\\n    0.2,\\n    0.21,\\n    0.22,\\n    0.23,\\n    0.24,\\n    0.25,\\n    0.26,\\n    0.27,\\n    0.28,\\n    0.29,\\n    0.3,\\n]  # bert base uncased\\npred_thresholds = [\\n    0.4,\\n    0.41,\\n    0.42,\\n    0.43,\\n    0.44,\\n    0.45,\\n    0.46,\\n    0.47,\\n    0.48,\\n    0.49,\\n    0.5,\\n]  # labse\\n# pred_thresholds = [\\n#     0.06,\\n#     0.07,\\n#     0.08,\\n#     0.09,\\n#     0.1,\\n#     0.11,\\n#     0.12,\\n#     0.13,\\n#     0.14,\\n#     0.15,\\n#     0.16,\\n#     0.17,\\n#     0.18,\\n#     0.19,\\n#     0.2,\\n#     0.11,\\n#     0.06,\\n# ]  # sentence-transformers\\n# pred_thresholds = [\\n#     0.6,\\n#     0.61,\\n#     0.62,\\n#     0.63,\\n#     0.64,\\n#     0.65,\\n#     0.66,\\n#     0.67,\\n#     0.68,\\n#     0.69,\\n#     0.7,\\n# ]  # USE\\n# pred_thresholds = [\\n#     0.65,\\n#     0.66,\\n#     0.67,\\n#     0.68,\\n#     0.69,\\n#     0.7,\\n#     0.71,\\n#     0.72,\\n#     0.73,\\n#     0.74,\\n#     0.75,\\n#     0.76,\\n#     0.77,\\n#     0.78,\\n#     0.79,\\n#     0.64,\\n# ]  # Roberta\";\n",
       "                var nbb_formatted_code = \"pred_thresholds = [\\n    0.2,\\n    0.21,\\n    0.22,\\n    0.23,\\n    0.24,\\n    0.25,\\n    0.26,\\n    0.27,\\n    0.28,\\n    0.29,\\n    0.3,\\n]  # bert base uncased\\npred_thresholds = [\\n    0.4,\\n    0.41,\\n    0.42,\\n    0.43,\\n    0.44,\\n    0.45,\\n    0.46,\\n    0.47,\\n    0.48,\\n    0.49,\\n    0.5,\\n]  # labse\\n# pred_thresholds = [\\n#     0.06,\\n#     0.07,\\n#     0.08,\\n#     0.09,\\n#     0.1,\\n#     0.11,\\n#     0.12,\\n#     0.13,\\n#     0.14,\\n#     0.15,\\n#     0.16,\\n#     0.17,\\n#     0.18,\\n#     0.19,\\n#     0.2,\\n#     0.11,\\n#     0.06,\\n# ]  # sentence-transformers\\n# pred_thresholds = [\\n#     0.6,\\n#     0.61,\\n#     0.62,\\n#     0.63,\\n#     0.64,\\n#     0.65,\\n#     0.66,\\n#     0.67,\\n#     0.68,\\n#     0.69,\\n#     0.7,\\n# ]  # USE\\n# pred_thresholds = [\\n#     0.65,\\n#     0.66,\\n#     0.67,\\n#     0.68,\\n#     0.69,\\n#     0.7,\\n#     0.71,\\n#     0.72,\\n#     0.73,\\n#     0.74,\\n#     0.75,\\n#     0.76,\\n#     0.77,\\n#     0.78,\\n#     0.79,\\n#     0.64,\\n# ]  # Roberta\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_thresholds = [\n",
    "    0.2,\n",
    "    0.21,\n",
    "    0.22,\n",
    "    0.23,\n",
    "    0.24,\n",
    "    0.25,\n",
    "    0.26,\n",
    "    0.27,\n",
    "    0.28,\n",
    "    0.29,\n",
    "    0.3,\n",
    "]  # bert base uncased\n",
    "pred_thresholds = [\n",
    "    0.4,\n",
    "    0.41,\n",
    "    0.42,\n",
    "    0.43,\n",
    "    0.44,\n",
    "    0.45,\n",
    "    0.46,\n",
    "    0.47,\n",
    "    0.48,\n",
    "    0.49,\n",
    "    0.5,\n",
    "]  # labse\n",
    "# pred_thresholds = [\n",
    "#     0.06,\n",
    "#     0.07,\n",
    "#     0.08,\n",
    "#     0.09,\n",
    "#     0.1,\n",
    "#     0.11,\n",
    "#     0.12,\n",
    "#     0.13,\n",
    "#     0.14,\n",
    "#     0.15,\n",
    "#     0.16,\n",
    "#     0.17,\n",
    "#     0.18,\n",
    "#     0.19,\n",
    "#     0.2,\n",
    "#     0.11,\n",
    "#     0.06,\n",
    "# ]  # sentence-transformers\n",
    "# pred_thresholds = [\n",
    "#     0.6,\n",
    "#     0.61,\n",
    "#     0.62,\n",
    "#     0.63,\n",
    "#     0.64,\n",
    "#     0.65,\n",
    "#     0.66,\n",
    "#     0.67,\n",
    "#     0.68,\n",
    "#     0.69,\n",
    "#     0.7,\n",
    "# ]  # USE\n",
    "# pred_thresholds = [\n",
    "#     0.65,\n",
    "#     0.66,\n",
    "#     0.67,\n",
    "#     0.68,\n",
    "#     0.69,\n",
    "#     0.7,\n",
    "#     0.71,\n",
    "#     0.72,\n",
    "#     0.73,\n",
    "#     0.74,\n",
    "#     0.75,\n",
    "#     0.76,\n",
    "#     0.77,\n",
    "#     0.78,\n",
    "#     0.79,\n",
    "#     0.64,\n",
    "# ]  # Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9cebcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_thresh = 0.4\n",
      "k = 5\n",
      "wd = 0.3082191780821918\n",
      "pk = 0.3082191780821918\n",
      "===========================================\n",
      "pred_thresh = 0.41\n",
      "k = 5\n",
      "wd = 0.3082191780821918\n",
      "pk = 0.3082191780821918\n",
      "===========================================\n",
      "pred_thresh = 0.42\n",
      "k = 5\n",
      "wd = 0.3082191780821918\n",
      "pk = 0.3082191780821918\n",
      "===========================================\n",
      "pred_thresh = 0.43\n",
      "k = 5\n",
      "wd = 0.3082191780821918\n",
      "pk = 0.3082191780821918\n",
      "===========================================\n",
      "pred_thresh = 0.44\n",
      "k = 5\n",
      "wd = 0.3082191780821918\n",
      "pk = 0.3082191780821918\n",
      "===========================================\n",
      "pred_thresh = 0.45\n",
      "k = 5\n",
      "wd = 0.3150684931506849\n",
      "pk = 0.3150684931506849\n",
      "===========================================\n",
      "pred_thresh = 0.46\n",
      "k = 5\n",
      "wd = 0.3150684931506849\n",
      "pk = 0.3150684931506849\n",
      "===========================================\n",
      "pred_thresh = 0.47\n",
      "k = 5\n",
      "wd = 0.2945205479452055\n",
      "pk = 0.2808219178082192\n",
      "===========================================\n",
      "pred_thresh = 0.48\n",
      "k = 5\n",
      "wd = 0.2945205479452055\n",
      "pk = 0.2808219178082192\n",
      "===========================================\n",
      "pred_thresh = 0.49\n",
      "k = 5\n",
      "wd = 0.3698630136986301\n",
      "pk = 0.3424657534246575\n",
      "===========================================\n",
      "pred_thresh = 0.5\n",
      "k = 5\n",
      "wd = 0.4315068493150685\n",
      "pk = 0.3904109589041096\n",
      "===========================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"for pred_thresh in pred_thresholds:\\n    modified_predictions = [\\n        1 if x < pred_thresh else 0 for x in [x[0] for x in predictions]\\n    ]\\n\\n    pred_string = \\\"\\\".join(str(modified_predictions))\\n    true_string = \\\"\\\".join(str(true_labels))\\n\\n    avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\\n\\n    wd_score = windowdiff(pred_string, true_string, avg_k)\\n    pk_score = pk(pred_string, true_string, avg_k)\\n\\n    print(f\\\"pred_thresh = {pred_thresh}\\\")\\n    print(f\\\"k = {avg_k}\\\")\\n    print(f\\\"wd = {wd_score}\\\")\\n    print(f\\\"pk = {pk_score}\\\")\\n    print(\\\"===========================================\\\")\";\n",
       "                var nbb_formatted_code = \"for pred_thresh in pred_thresholds:\\n    modified_predictions = [\\n        1 if x < pred_thresh else 0 for x in [x[0] for x in predictions]\\n    ]\\n\\n    pred_string = \\\"\\\".join(str(modified_predictions))\\n    true_string = \\\"\\\".join(str(true_labels))\\n\\n    avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\\n\\n    wd_score = windowdiff(pred_string, true_string, avg_k)\\n    pk_score = pk(pred_string, true_string, avg_k)\\n\\n    print(f\\\"pred_thresh = {pred_thresh}\\\")\\n    print(f\\\"k = {avg_k}\\\")\\n    print(f\\\"wd = {wd_score}\\\")\\n    print(f\\\"pk = {pk_score}\\\")\\n    print(\\\"===========================================\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pred_thresh in pred_thresholds:\n",
    "    modified_predictions = [\n",
    "        1 if x < pred_thresh else 0 for x in [x[0] for x in predictions]\n",
    "    ]\n",
    "\n",
    "    pred_string = \"\".join(str(modified_predictions))\n",
    "    true_string = \"\".join(str(true_labels))\n",
    "\n",
    "    avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\n",
    "\n",
    "    wd_score = windowdiff(pred_string, true_string, avg_k)\n",
    "    pk_score = pk(pred_string, true_string, avg_k)\n",
    "\n",
    "    print(f\"pred_thresh = {pred_thresh}\")\n",
    "    print(f\"k = {avg_k}\")\n",
    "    print(f\"wd = {wd_score}\")\n",
    "    print(f\"pk = {pk_score}\")\n",
    "    print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a2f65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"from sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import precision_recall_fscore_support\\n\\nprint(pred_string)\\nprint(true_string)\\n\\ntn, fp, fn, tp = confusion_matrix(true_labels, modified_predictions).ravel()\\nprecision, recall, f1, _ = precision_recall_fscore_support(\\n    true_labels, modified_predictions, average=\\\"macro\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"from sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import precision_recall_fscore_support\\n\\nprint(pred_string)\\nprint(true_string)\\n\\ntn, fp, fn, tp = confusion_matrix(true_labels, modified_predictions).ravel()\\nprecision, recall, f1, _ = precision_recall_fscore_support(\\n    true_labels, modified_predictions, average=\\\"macro\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(pred_string)\n",
    "print(true_string)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(true_labels, modified_predictions).ravel()\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    true_labels, modified_predictions, average=\"macro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9dbb752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6\n",
      "wd = 0.3076751946607342\n",
      "pk = 0.30567296996662957\n",
      "tn = 1203\n",
      "fp = 55\n",
      "fn = 215\n",
      "tp = 27\n",
      "precision = 0.5888231449310262\n",
      "recall = 0.533925028577435\n",
      "f1 = 0.5328849028400597\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\\nprint(f\\\"tn = {tn}\\\")\\nprint(f\\\"fp = {fp}\\\")\\nprint(f\\\"fn = {fn}\\\")\\nprint(f\\\"tp = {tp}\\\")\\nprint(f\\\"precision = {precision}\\\")\\nprint(f\\\"recall = {recall}\\\")\\nprint(f\\\"f1 = {f1}\\\")\";\n",
       "                var nbb_formatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\\nprint(f\\\"tn = {tn}\\\")\\nprint(f\\\"fp = {fp}\\\")\\nprint(f\\\"fn = {fn}\\\")\\nprint(f\\\"tp = {tp}\\\")\\nprint(f\\\"precision = {precision}\\\")\\nprint(f\\\"recall = {recall}\\\")\\nprint(f\\\"f1 = {f1}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wd_score = windowdiff(pred_string, true_string, avg_k)\n",
    "pk_score = pk(pred_string, true_string, avg_k)\n",
    "\n",
    "print(f\"k = {avg_k}\")\n",
    "print(f\"wd = {wd_score}\")\n",
    "print(f\"pk = {pk_score}\")\n",
    "print(f\"tn = {tn}\")\n",
    "print(f\"fp = {fp}\")\n",
    "print(f\"fn = {fn}\")\n",
    "print(f\"tp = {tp}\")\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "print(f\"f1 = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34585627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "462a8434",
   "metadata": {},
   "source": [
    "## KeyBERT Embedding Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d15e7648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 172;\n",
       "                var nbb_unformatted_code = \"curr = 230\\nprev = curr - 1\";\n",
       "                var nbb_formatted_code = \"curr = 230\\nprev = curr - 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curr = 230\n",
    "prev = curr - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the keywords and embeddings library\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "similarities_lib = Similarities(\"bert-base-uncased\")\n",
    "keywords_lib = Keywords(similarities_lib.model, similarities_lib.tokenizer)\n",
    "embedding_lib = Embedding(similarities_lib.model, similarities_lib.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8c6434ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the keywords in 0.6567 seconds\n",
      "Got the embeddings and comparisons in 0.0007 seconds\n",
      "['cantonese', 'languages', 'vietnamese', 'communes']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"cohesion = coherence.get_coherence(\\n    [text_data[curr], text_data[prev]], coherence_threshold=0.25\\n)\\nprint([k[0] for k in cohesion])\";\n",
       "                var nbb_formatted_code = \"cohesion = coherence.get_coherence(\\n    [text_data[curr], text_data[prev]], coherence_threshold=0.25\\n)\\nprint([k[0] for k in cohesion])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cohesion = coherence.get_coherence(\n",
    "    [text_data[curr], text_data[prev]], coherence_threshold=0.25\n",
    ")\n",
    "print([k[0] for k in cohesion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "357c0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"# get the keywords for the current sentences\\nkeywords_current = keywords_lib.get_keywords_with_kb_embeddings(text_data[curr])\\nkeywords_prev = keywords_lib.get_keywords_with_kb_embeddings(text_data[prev])\\n\\n# compute the word comparisons between the previous (with the coherence map)\\n# and the current (possibly the first sentence in a new segment)\\nword_comparisons_with_coherence, weights = compare_coherent_words(\\n    [keywords_prev], keywords_current\\n)\";\n",
       "                var nbb_formatted_code = \"# get the keywords for the current sentences\\nkeywords_current = keywords_lib.get_keywords_with_kb_embeddings(text_data[curr])\\nkeywords_prev = keywords_lib.get_keywords_with_kb_embeddings(text_data[prev])\\n\\n# compute the word comparisons between the previous (with the coherence map)\\n# and the current (possibly the first sentence in a new segment)\\nword_comparisons_with_coherence, weights = compare_coherent_words(\\n    [keywords_prev], keywords_current\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the keywords for the current sentences\n",
    "keywords_current = keywords_lib.get_keywords_with_kb_embeddings(text_data[curr])\n",
    "keywords_prev = keywords_lib.get_keywords_with_kb_embeddings(text_data[prev])\n",
    "\n",
    "# compute the word comparisons between the previous (with the coherence map)\n",
    "# and the current (possibly the first sentence in a new segment)\n",
    "word_comparisons_with_coherence, weights = compare_coherent_words(\n",
    "    [keywords_prev], keywords_current\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dd52c9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('township', 0.2304),\n",
       "  ('communes', 0.1857),\n",
       "  ('hải', 0.1399),\n",
       "  ('wards', 0.1397),\n",
       "  ('đông', 0.1224)],\n",
       " [('cantonese', 0.5038),\n",
       "  ('mandarin', 0.464),\n",
       "  ('languages', 0.3483),\n",
       "  ('language', 0.343),\n",
       "  ('vietnamese', 0.3184)])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 207;\n",
       "                var nbb_unformatted_code = \"[(x[0], x[1]) for x in keywords_current], [(x[0], x[1]) for x in keywords_prev]\";\n",
       "                var nbb_formatted_code = \"[(x[0], x[1]) for x in keywords_current], [(x[0], x[1]) for x in keywords_prev]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[(x[0], x[1]) for x in keywords_current], [(x[0], x[1]) for x in keywords_prev]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121f953",
   "metadata": {},
   "source": [
    "# KeyBERT Embedding Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "559ab602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 679;\n",
       "                var nbb_unformatted_code = \"docs = [\\n        \\\"Hi my name is Devarsh\\\",\\n        \\\"Devarsh likes to play Basketball.\\\",\\n    \\\"I love to watch Cricket.\\\",\\n        \\\"I am a strong programmer. And my name is Devarsh\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"docs = [\\n    \\\"Hi my name is Devarsh\\\",\\n    \\\"Devarsh likes to play Basketball.\\\",\\n    \\\"I love to watch Cricket.\\\",\\n    \\\"I am a strong programmer. And my name is Devarsh\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = [\n",
    "    \"Hi my name is Devarsh\",\n",
    "    \"Devarsh likes to play Basketball.\",\n",
    "    \"I love to watch Cricket.\",\n",
    "    \"I am a strong programmer. And my name is Devarsh\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "00458200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 680;\n",
       "                var nbb_unformatted_code = \"from keybert import KeyBERT\\n\\nkw_model = KeyBERT()\\ndoc_embeddings, word_embeddings = kw_model.extract_embeddings(\\n    docs, min_df=1, stop_words=\\\"english\\\"\\n)\\nkeywords = kw_model.extract_keywords(\\n    docs,\\n    min_df=1,\\n    stop_words=\\\"english\\\",\\n    doc_embeddings=doc_embeddings,\\n    word_embeddings=word_embeddings,\\n)\";\n",
       "                var nbb_formatted_code = \"from keybert import KeyBERT\\n\\nkw_model = KeyBERT()\\ndoc_embeddings, word_embeddings = kw_model.extract_embeddings(\\n    docs, min_df=1, stop_words=\\\"english\\\"\\n)\\nkeywords = kw_model.extract_keywords(\\n    docs,\\n    min_df=1,\\n    stop_words=\\\"english\\\",\\n    doc_embeddings=doc_embeddings,\\n    word_embeddings=word_embeddings,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "doc_embeddings, word_embeddings = kw_model.extract_embeddings(\n",
    "    docs, min_df=1, stop_words=\"english\"\n",
    ")\n",
    "keywords = kw_model.extract_keywords(\n",
    "    docs,\n",
    "    min_df=1,\n",
    "    stop_words=\"english\",\n",
    "    doc_embeddings=doc_embeddings,\n",
    "    word_embeddings=word_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "7d30bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 681;\n",
       "                var nbb_unformatted_code = \"len(doc_embeddings)\";\n",
       "                var nbb_formatted_code = \"len(doc_embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "018ee52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 682;\n",
       "                var nbb_unformatted_code = \"len(word_embeddings)\";\n",
       "                var nbb_formatted_code = \"len(word_embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "80cbdc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('devarsh', 0.6267), ('hi', 0.5216)],\n",
       " [('devarsh', 0.6549),\n",
       "  ('basketball', 0.5558),\n",
       "  ('play', 0.3787),\n",
       "  ('likes', 0.2284)],\n",
       " [('cricket', 0.7118), ('watch', 0.3656), ('love', 0.307)],\n",
       " [('programmer', 0.5942), ('devarsh', 0.5528), ('strong', 0.3452)]]"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 683;\n",
       "                var nbb_unformatted_code = \"keywords\";\n",
       "                var nbb_formatted_code = \"keywords\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "fd1ac50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 701;\n",
       "                var nbb_unformatted_code = \"kw_model = KeyBERT()\\nimport torch\\n\\n\\ndef get_keywords_with_embeddings_test(\\n    data,\\n) -> list[tuple[str, float, torch.Tensor]]:\\n    doc_embeddings, word_embeddings = kw_model.extract_embeddings(data)\\n\\n    keywords = kw_model.extract_keywords(\\n        data, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings\\n    )\\n\\n    keywords_with_embeddings = []\\n    count = 0\\n    print(len(word_embeddings))\\n    for i, (kw, we) in enumerate(zip(keywords, word_embeddings)):\\n        for j, words in enumerate(kw):\\n            keywords_with_embeddings.append((words[0], words[1], torch.tensor(we)))\\n            count += 1\\n\\n    return keywords_with_embeddings\";\n",
       "                var nbb_formatted_code = \"kw_model = KeyBERT()\\nimport torch\\n\\n\\ndef get_keywords_with_embeddings_test(\\n    data,\\n) -> list[tuple[str, float, torch.Tensor]]:\\n    doc_embeddings, word_embeddings = kw_model.extract_embeddings(data)\\n\\n    keywords = kw_model.extract_keywords(\\n        data, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings\\n    )\\n\\n    keywords_with_embeddings = []\\n    count = 0\\n    print(len(word_embeddings))\\n    for i, (kw, we) in enumerate(zip(keywords, word_embeddings)):\\n        for j, words in enumerate(kw):\\n            keywords_with_embeddings.append((words[0], words[1], torch.tensor(we)))\\n            count += 1\\n\\n    return keywords_with_embeddings\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kw_model = KeyBERT()\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_keywords_with_embeddings_test(\n",
    "    data,\n",
    ") -> list[tuple[str, float, torch.Tensor]]:\n",
    "    doc_embeddings, word_embeddings = kw_model.extract_embeddings(data)\n",
    "\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        data, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings\n",
    "    )\n",
    "\n",
    "    keywords_with_embeddings = []\n",
    "    count = 0\n",
    "    print(len(word_embeddings))\n",
    "    for i, (kw, we) in enumerate(zip(keywords, word_embeddings)):\n",
    "        for j, words in enumerate(kw):\n",
    "            keywords_with_embeddings.append((words[0], words[1], torch.tensor(we)))\n",
    "            count += 1\n",
    "\n",
    "    return keywords_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "d1bbf3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 702;\n",
       "                var nbb_unformatted_code = \"embeddings = get_keywords_with_embeddings_test(docs)\";\n",
       "                var nbb_formatted_code = \"embeddings = get_keywords_with_embeddings_test(docs)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = get_keywords_with_embeddings_test(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "f1ea7b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 703;\n",
       "                var nbb_unformatted_code = \"len(embeddings)\";\n",
       "                var nbb_formatted_code = \"len(embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883ef15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
